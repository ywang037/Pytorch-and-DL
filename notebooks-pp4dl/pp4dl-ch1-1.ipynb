{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5296a31",
   "metadata": {},
   "source": [
    "### pp4dl notebook 1-1\n",
    "##### Summary\n",
    "This is the first self learning hands-on notebook for book *Programming PyTorch for Deep Learning* (pp4dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2715a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c96c06",
   "metadata": {},
   "source": [
    "##### Basic operations\n",
    "\n",
    "Other than what is shown in chapter 1 of the book *PyTorch recipes: a problem-solution approach*, basic tensor operations can be done more easily by directly using the operands or using methods provided in the `Tensor` class, without the hassle of using `torch.something()` (e.g., `torch.add()`, `torch.mul()`). See the official <a href=\"https://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html#operations-on-tensors\">tutorial</a> as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2655f874",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(6) # this gives you a vector of dimension=6\n",
    "v = torch.rand(6)\n",
    "a = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "620ccbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor sum\n",
    "y1 = x + v\n",
    "y2 = x.add(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b32075c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0198, 0.8215, 1.6252, 1.4219, 0.7120, 1.0644])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4e2d175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0198, 0.8215, 1.6252, 1.4219, 0.7120, 1.0644])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e44e4a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True, True])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1==y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7edb6784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(y1,y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "985d106e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8915, 3.9878, 4.8932, 3.2829, 0.0614, 1.5882])\n",
      "tensor([0.8915, 3.9878, 4.8932, 3.2829, 0.0614, 1.5882])\n"
     ]
    }
   ],
   "source": [
    "# tensor multiply with constant\n",
    "print(x.mul(a))\n",
    "print(x * a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5686bf76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1295, 0.1042, 0.6603, 0.4786, 0.0072, 0.2117])\n",
      "tensor([0.1295, 0.1042, 0.6603, 0.4786, 0.0072, 0.2117])\n"
     ]
    }
   ],
   "source": [
    "# entry-wise tensor multiplication\n",
    "print(x.mul(v))\n",
    "print(x * v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d177b7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5915)\n",
      "tensor(1.5915)\n"
     ]
    }
   ],
   "source": [
    "# linear algebra muliplication\n",
    "print(x.matmul(v))\n",
    "print(x @ v) # note that the symbol @ works as the operands for inner-product of two vectors that are dimensionally compatitable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8938c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5914591550827026"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using method item() to extract the value of a scalar, zero-dimension, tensor\n",
    "x.matmul(v).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d173213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5914591550827026"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x @ v).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1669c4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W is a 2-by-6 matrix\n"
     ]
    }
   ],
   "source": [
    "# Product between matrix and vector in a linear algebra manner\n",
    "W = torch.rand(2,6)\n",
    "print(f'W is a {W.shape[0]}-by-{W.size()[1]} matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8473916c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1986, 1.7664])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.matmul(W.T) # in this way, vector x will be treated as a row vector of 1x6, so we need to transpose matrix W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "eb8a67ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1986, 1.7664])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x @ W.T # this is equivalent to the above line of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4e65436d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1986, 1.7664])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.matmul(x) # in this way, x will be automatically interpreted as a column vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "65f20fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1986, 1.7664])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W @ x # in this way, x will be automatically interpreted as a column vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "758702ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall that W is a 2-by-6 matrix\n",
      "Vector x has a dimension of 6, the operaiton W*x gives the following matrix\n",
      "\n",
      "tensor([[2.1768e-02, 5.5741e-01, 4.2259e-01, 3.2947e-03, 2.7193e-04, 1.9330e-01],\n",
      "        [3.4191e-02, 3.0405e-01, 7.2417e-01, 5.0596e-01, 6.1589e-03, 1.9187e-01]])\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Product between matrix and vector in element-wise manner\n",
    "print(f'Recall that W is a {W.shape[0]}-by-{W.size()[1]} matrix')\n",
    "print(f'Vector x has a dimension of {x.shape[-1]}, the operaiton W*x gives the following matrix\\n')\n",
    "print(W*x) # each row of W will be multiplied by vector x in an element-wise manner \n",
    "print(torch.equal(W*x,x*W))\n",
    "print(torch.equal(W.mul(x),W*x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a1602893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.FloatTensor\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# type of a tensor\n",
    "print(x.matmul(v).type())\n",
    "print(x.matmul(v).dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4f41a832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectors x and y has dimension 6 and 6 respectively\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "# shape or size of a tensor\n",
    "print(f'vectors x and y has dimension {x.shape[-1]} and {v.size()[-1]} respectively') # in [-1], -1 is to denote the default dimension which is same as leaving blank [] in matlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8f2410a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5914591550827026 is a zero-dimensional tensor, its size is torch.Size([])\n",
      "tensor([1.5915]) is a one-dimensional tensor, it size is torch.Size([1])\n",
      "tensor([1.5915]) is a 1-dimensional tensor\n"
     ]
    }
   ],
   "source": [
    "# dimensionality of tensors\n",
    "print(f'{x.matmul(v)} is a zero-dimensional tensor, its size is {x.matmul(v).shape}')\n",
    "print(f'{x.matmul(v).reshape(1,)} is a one-dimensional tensor, it size is {x.matmul(v).reshape(1,).shape}') # use reshape() to change the shape of the tensor, just like the matlab\n",
    "print(f'{x.matmul(v).reshape(1,)} is a {x.matmul(v).reshape(1,).shape[-1]}-dimensional tensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b0b00fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W is a matrix of 2x6\n",
      "\n",
      "Now we want to concatenate x with vector v, by putting x above or below v to form a matrix of 2x6\n",
      "\n",
      "But we must first convert vectors x, v into a 2-D tensors\n",
      "\n",
      "Note the original vector x:\n",
      "tensor([0.1486, 0.6646, 0.8155, 0.5471, 0.0102, 0.2647])\n",
      "\n",
      "Note the converted vector x with increased dimension, an addition pair of [] appears\n",
      "tensor([[0.1486, 0.6646, 0.8155, 0.5471, 0.0102, 0.2647]])\n",
      "\n",
      "Let's apply same technique to vector v, then we do the concatenation and see\n",
      "tensor([[0.1486, 0.6646, 0.8155, 0.5471, 0.0102, 0.2647],\n",
      "        [0.8712, 0.1568, 0.8096, 0.8748, 0.7018, 0.7997]])\n"
     ]
    }
   ],
   "source": [
    "# increase the dimensionality before doing concatenation\n",
    "print(f'W is a matrix of {W.shape[0]}x{W.size()[1]}')\n",
    "print(f'\\nNow we want to concatenate x with vector v, by putting x above or below v to form a matrix of 2x{x.size()[-1]}')\n",
    "print('\\nBut we must first convert vectors x, v into a 2-D tensors')\n",
    "print('\\nNote the original vector x:')\n",
    "print(x)\n",
    "#print(x.shape)\n",
    "print('\\nNote the converted vector x with increased dimension, an addition pair of [] appears')\n",
    "x_new = x.reshape(1,len(x))\n",
    "print(x_new)\n",
    "v_new = v.reshape(1,len(v))\n",
    "X = torch.cat((x_new,v_new),0)\n",
    "print(f'\\nLet\\'s apply same technique to vector v, then we do the concatenation and see\\n{X}')\n",
    "# torch.cat((x_new,v_new),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "abf2567f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our matrix A looks like this:\n",
      "tensor([[[1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1.]]])\n",
      "\n",
      "Our matrix B looks like this:\n",
      "tensor([[[2., 2., 2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2., 2., 2.]]])\n",
      "\n",
      "Concatenation of A above B looks like this:\n",
      "tensor([[[1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[2., 2., 2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2., 2., 2.]]])\n"
     ]
    }
   ],
   "source": [
    "# Permute the dimension order of a tensor\n",
    "\n",
    "# # increase the dimensionality of matrix W, so that it is a 3-D tensor now\n",
    "# W_new = W.reshape(1,W.shape[0],-1)\n",
    "# print(f'W_new now looks like this\\n{W_new}')\n",
    "# X_new = X.reshape_as(W_new) # use method reshape_as() for similicity to make the shape of X_new the same as W_new\n",
    "# print(f'\\nX_new looks like this\\n{X_new}')\n",
    "# M = torch.cat((W_new,X_new),dim=0)\n",
    "# print(f'\\nThe concatenation of W_new and X_new makes a 3-D tensor:\\n{M}')\n",
    "\n",
    "A = torch.ones(1,3,6)\n",
    "print(f'Our matrix A looks like this:\\n{A}')\n",
    "B = A.mul(2)\n",
    "print(f'\\nOur matrix B looks like this:\\n{B}')\n",
    "C = torch.cat((A,B),dim=0)\n",
    "print(f'\\nConcatenation of A above B looks like this:\\n{C}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "853bd9aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[2., 2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2., 2.]]])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.permute(0,1,2) # note the order and name of dimensions, this line actually change nothing of the dimension order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "d982c4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 2.],\n",
      "         [1., 2.],\n",
      "         [1., 2.],\n",
      "         [1., 2.],\n",
      "         [1., 2.],\n",
      "         [1., 2.]],\n",
      "\n",
      "        [[1., 2.],\n",
      "         [1., 2.],\n",
      "         [1., 2.],\n",
      "         [1., 2.],\n",
      "         [1., 2.],\n",
      "         [1., 2.]],\n",
      "\n",
      "        [[1., 2.],\n",
      "         [1., 2.],\n",
      "         [1., 2.],\n",
      "         [1., 2.],\n",
      "         [1., 2.],\n",
      "         [1., 2.]]])\n",
      "torch.Size([3, 6, 2])\n",
      "\n",
      "Each \"layer\" of the tensor is\n",
      "tensor([[1., 2.],\n",
      "        [1., 2.],\n",
      "        [1., 2.],\n",
      "        [1., 2.],\n",
      "        [1., 2.],\n",
      "        [1., 2.]])\n"
     ]
    }
   ],
   "source": [
    "print(C.permute(1,2,0))\n",
    "print(C.permute(1,2,0).size())\n",
    "print(f'\\nEach \"layer\" of the tensor is\\n{C.permute(1,2,0)[0,:,:]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "03c07689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 1., 1.],\n",
      "         [2., 2., 2.]],\n",
      "\n",
      "        [[1., 1., 1.],\n",
      "         [2., 2., 2.]],\n",
      "\n",
      "        [[1., 1., 1.],\n",
      "         [2., 2., 2.]],\n",
      "\n",
      "        [[1., 1., 1.],\n",
      "         [2., 2., 2.]],\n",
      "\n",
      "        [[1., 1., 1.],\n",
      "         [2., 2., 2.]],\n",
      "\n",
      "        [[1., 1., 1.],\n",
      "         [2., 2., 2.]]])\n",
      "torch.Size([6, 2, 3])\n",
      "\n",
      "Each \"layer\" of the tensor is\n",
      "tensor([[1., 1., 1.],\n",
      "        [2., 2., 2.]])\n"
     ]
    }
   ],
   "source": [
    "print(C.permute(2,0,1))\n",
    "print(C.permute(2,0,1).size())\n",
    "print(f'\\nEach \"layer\" of the tensor is\\n{C.permute(2,0,1)[0,:,:]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "9c562c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 2.],\n",
      "         [1., 2.],\n",
      "         [1., 2.]],\n",
      "\n",
      "        [[1., 2.],\n",
      "         [1., 2.],\n",
      "         [1., 2.]],\n",
      "\n",
      "        [[1., 2.],\n",
      "         [1., 2.],\n",
      "         [1., 2.]],\n",
      "\n",
      "        [[1., 2.],\n",
      "         [1., 2.],\n",
      "         [1., 2.]],\n",
      "\n",
      "        [[1., 2.],\n",
      "         [1., 2.],\n",
      "         [1., 2.]],\n",
      "\n",
      "        [[1., 2.],\n",
      "         [1., 2.],\n",
      "         [1., 2.]]])\n",
      "torch.Size([6, 3, 2])\n",
      "\n",
      "Each \"layer\" of the tensor is\n",
      "tensor([[1., 2.],\n",
      "        [1., 2.],\n",
      "        [1., 2.]])\n"
     ]
    }
   ],
   "source": [
    "print(C.permute(2,1,0))\n",
    "print(C.permute(2,1,0).size())\n",
    "print(f'\\nEach \"layer\" of the tensor is\\n{C.permute(2,1,0)[0,:,:]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b58bac",
   "metadata": {},
   "source": [
    "##### Quick summary of `permute()` and dimension orders in PyTorch\n",
    "\n",
    "1. 正如上方的代码所示，在PyTorch中，无论Tensor有多少维度，“0” 代表其最高维度，“1” 和 “2” 代表第二、第三维度。\n",
    "    * 例如，一个3-D Tensor，可以将其想象成$N$个/层矩阵叠起来，则0代表数据按层叠加的方向/维度，1代表每层矩阵中数据排成一列的方向/维度，2代表每层矩阵中数据排成一行的方向/维度\n",
    "    * 或者例如一个2-D Tensor，其实就是一个矩阵，这时0为最高维度，1是第二维度，没有第三维度；这样，0就代表该矩阵中数据排成一列的方向/维度，1则代表该矩阵中数据排成一行的方向/维度。例如我们有一个矩阵$\\mathbf{A}\\in\\mathbb{R}^{m\\times n}$，\n",
    "        * 使用`A.sum(dim=0)`我们将得到一个 $n$ 维（行）向量 $\\mathbf{a}=[a_1,a_2,\\dots,a_n]$, 其中$a_i=\\sum_{j=1}^{m}A_{i,j}, \\forall i=1,2,\\dots,n$\n",
    "        * 同理，`A.sum(dim=1)`将输出一个 $m$ 维（列）向量 $\\mathbf{a}=[a_1,a_2,\\dots,a_m]^T$, 其中$a_j=\\sum_{i=1}^{n}A_{i,j}, \\forall j=1,2,\\dots,m$\n",
    "        \n",
    "2. 使用`permute()`可以灵活的交换Tensor的各个维度，如同将一个“方块”进行旋转。可以将“方块”从正上方所看到的形状，想象成Tensor通过`permute()`交换维度之后，每一层数据的形状，如下图所示\n",
    "![permute oder](./permute-tensor-dimension-order.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb59c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory saving operation like add_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
