{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ac72bda",
   "metadata": {},
   "source": [
    "### Summary\n",
    "In this note, we study how to generate random numbers using different distributions.\n",
    "\n",
    "Basically, there are **two ways** to generate random numbers:\n",
    "1. use *pytorch functions or methods* like `torch.Tensor().uniform_()`, `torch.bernoulli()`, and `torch.multinomial()`.\n",
    "\n",
    "    This approach is more straightforward to use, but it is not so flexible and powerful as the 2nd approach below. Docments for some mostly used distribution is listed below\n",
    "    * Uniform distribution in $[a,b]$, `torch.Tensor(input).uniform_(a,b)` see <a href=\"https://pytorch.org/docs/1.8.1/tensors.html?highlight=uniform#torch.Tensor.uniform_\">here</a> for reference\n",
    "    * Bernoulli distribution `torch.bernoulli(input)` with probabilities specifed in the *input* tensor argument, see <a href=\"https://pytorch.org/docs/1.8.1/generated/torch.bernoulli.html#torch-bernoulli\">here</a> for the reference\n",
    "    * Multinomial distribution `torch.multinomial(input)` with probability (or weights) specified by the *input* tensor, see <a href=\"https://pytorch.org/docs/1.8.1/generated/torch.multinomial.html#torch-multinomial\">here</a> for the reference\n",
    "    * Normal distribution `torch.normal(mean,std)`, see <a href=\"https://pytorch.org/docs/1.8.1/generated/torch.normal.html#torch-normal\">here</a> for the reference\n",
    "\n",
    "\n",
    "2. use *pytorch class* like `torch.distributions.binomial.Binomial` to generate a desired distribution first, e.g., `my_distribution`, then use *method* like `my_distribution.sample()` to get the random numbers out of the generated distribution. \n",
    "\n",
    "    This approach allows for more customization for the desired distribution from which to generate the random numbers. The referenes and examples for some mostly used distrubtions are listed below\n",
    "    * <a href=\"https://pytorch.org/docs/1.8.1/distributions.html#torch.distributions.bernoulli.Bernoulli\"> Bernoulli distribution </a> \n",
    "    * <a href=\"https://pytorch.org/docs/1.8.1/distributions.html#torch.distributions.binomial.Binomial\"> Binomial distribution </a>\n",
    "    * <a href=\"https://pytorch.org/docs/1.8.1/distributions.html#torch.distributions.multinomial.Multinomial\"> Multinomial distribution </a>\n",
    "    * <a href=\"https://pytorch.org/docs/1.8.1/distributions.html#torch.distributions.normal.Normal\"> Normal distribution </a> and <a href=\"https://pytorch.org/docs/1.8.1/distributions.html#torch.distributions.multinomial.Multinomial\"> multivariate normal distribution </a>\n",
    "    \n",
    "**In this note, we use the first approach listed above.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "292f684d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3e972b",
   "metadata": {},
   "source": [
    "##### Seed\n",
    "Firstly, let's make our own seed for random number generator, as is in the Matlab. So that we can fix the batches of random numbers to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72e348ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "666"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myseed = 666\n",
    "myseed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a07b26f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.1188,  0.0635, -1.4555, -0.0126])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(myseed)\n",
    "torch.randn(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a83625e",
   "metadata": {},
   "source": [
    "##### Normal distrubtion\n",
    "Now we use the seed to generate tensors using standard normal distrubtion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0dfbf2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7747,  0.7926, -0.0062, -0.4377],\n",
       "        [ 0.4657, -0.1880, -0.8975,  0.4169],\n",
       "        [-0.3840,  0.0394,  0.4869, -0.1476],\n",
       "        [-0.4459, -0.0336,  0.0221, -0.0550]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(myseed)\n",
    "rvn1 = torch.randn(4,4) # generate a 4-by-4 tensor with standard normal distribution \n",
    "rvn1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c106e1",
   "metadata": {},
   "source": [
    "Alternatively, one can do the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "874097ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9645,  0.0285, -0.3170,  1.6640],\n",
       "        [ 0.7148,  0.3590, -0.1242,  2.0345],\n",
       "        [ 0.9017, -1.1558,  0.1841,  0.0934],\n",
       "        [ 0.3168, -0.8889,  1.1768,  0.8074]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rvn2 = torch.normal(mean=0,std=1,size=(4,4)) # here the normal distribution is used\n",
    "rvn2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c7f81f",
   "metadata": {},
   "source": [
    "One can also specified the mean and std to using tensors **of same size**, in this case, the function can generate an output tensor that has the same size as the input mean and std tensor, each elment in the output tensor is generated as per the element specified in the mean tensor and std tensor correspondinly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fda7ff48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6975, 2.3782])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_mean = [1., 2.]\n",
    "my_std = [.2, .5]\n",
    "mean = torch.tensor(my_mean) # two different means\n",
    "std = torch.tensor(my_std) # two different std\n",
    "rvn3 = torch.normal(mean,std) # here the normal distribution is used\n",
    "rvn3 # two random numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3466e25e",
   "metadata": {},
   "source": [
    "Note that in the above generated tensor, the first element is generated from $\\mathcal{N}(1.0,\\sqrt{0.2})$, and the second one is from $\\mathcal{N}(2.0,\\sqrt{0.5})$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32d33cb",
   "metadata": {},
   "source": [
    "##### Uniform and Bernoulli distribution\n",
    "Now, let's first draw numbers from a unifrom distribution in $[0,1]$, then use these randomly generated numbers to denote the probabilities that we gonna use for obtaining random numbers from a Bernoulli distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98596ec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6167, 0.4009, 0.2426, 0.0523],\n",
       "        [0.4494, 0.3270, 0.1688, 0.5733],\n",
       "        [0.3116, 0.2653, 0.6158, 0.8620],\n",
       "        [0.3405, 0.7099, 0.0871, 0.5649]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ud_from = 0\n",
    "ud_to = 1\n",
    "rvu = torch.Tensor(4,4).uniform_(ud_from,ud_to) # here the uniform distribution is used\n",
    "rvu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "def4d472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 1., 1.],\n",
       "        [1., 1., 1., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rvbern = torch.bernoulli(rvu) # here the bernoulli distribution is used\n",
    "rvbern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38cd60c",
   "metadata": {},
   "source": [
    "##### Multinomial distribution\n",
    "When using `torch.multinomial(P, num_samples, replacement)` to generate random numbers, one should first use a **non-negative** tensor $P$ to specify the probabilities or weights for each of the events, there must be **at least one non-zero element** in $P$:\n",
    "* in case $P$ is a vector, say $P=[p_1,\\dots,p_N]$, then each element $p_i,i=1\\dots,N$ denotes the probabilities or weights for event $i$: if $P$ sums up to one, then $p_i$ denotes the related probabilites, if not, then elements of $P$ will be treated as weights (then being normalized to denote the prabilities). Input `num_samples` **must not** be larger than $N$ if `replacement=false` which is default when left blank.\n",
    "* in case $P$ is a matrix, then each row of $P$ will be used correspondingly as described above. If $P$ has $m$ rows, then a tensor of $m$-by-`num_samples` will be generated as the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bd26f0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is the 10 probabilities/weights we gonna use for bernoulli distribution\n",
      "tensor([ 4.,  5.,  9.,  2.,  8.,  1.,  0.,  3.,  6., 10.,  7.])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(myseed)\n",
    "P1 = torch.randperm(11).float()\n",
    "print('Below is the 10 probabilities/weights we gonna use for bernoulli distribution')\n",
    "print(P1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "05821b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 7])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rvb_1 = torch.multinomial(P1,3)\n",
    "rvb_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d5decb08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3, 1])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P2 = torch.tensor([0, 0.1, 0.5, 0.3, 0, 0.1])\n",
    "rvb_2 = torch.multinomial(P2,3)\n",
    "rvb_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111936a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
