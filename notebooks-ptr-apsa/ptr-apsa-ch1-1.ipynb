{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2bedf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98767bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.version.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36c80af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2fc92c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rand = torch.rand(shape) # this is psuedo random numbers generated from uniform distribution [0,1]\n",
    "X_randn = torch.randn(shape) # this generates psuedo random numbers from standard normal distribution\n",
    "X_randperm = torch.randperm(10) # this generates psuedo random intergers from 0 to n-1\n",
    "X_ones = torch.ones(shape)\n",
    "X_zeros = torch.zeros(shape)\n",
    "X_eye = torch.eye(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f5baf5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9792, 0.7624, 0.8077],\n",
      "        [0.5812, 0.5710, 0.8839]])\n",
      "tensor([[ 1.0053,  0.4050,  1.7793],\n",
      "        [ 0.3208, -0.2541, -0.4931]])\n",
      "tensor([1, 3, 0, 5, 2, 7, 6, 9, 4, 8])\n",
      "tensor([1, 1])\n",
      "tensor([0, 0, 0])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "print(X_rand)\n",
    "print(X_randn)\n",
    "print(X_randperm)\n",
    "print(torch.argmin(X_rand,dim=1)) # this returns the indices of minimum value in the argument tensor, serached by rows\n",
    "print(torch.argmax(X_randn,dim=0)) # this returns the indices of maximum value in the argument tensor, serached by colunms\n",
    "print(X_ones)\n",
    "print(X_zeros)\n",
    "print(X_eye)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8506ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(X_rand.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0924eb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]], dtype=torch.float64)\n",
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "X_zero_2 = torch.zeros_like(X_eye,dtype=torch.double)\n",
    "print(X_zero_2)\n",
    "print(X_zero_2.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62c78816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 6, 6, 8, 8, 8, 5, 2, 0]\n",
      "tensor([6., 6., 6., 8., 8., 8., 5., 2., 0.])\n",
      "<class 'list'>\n",
      "<class 'torch.Tensor'>\n",
      "torch.float32\n",
      "[6.0, 6.0, 6.0, 8.0, 8.0, 8.0, 5.0, 2.0, 0.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [6,6,6,8,8,8,5,2,0]\n",
    "print(x)\n",
    "xt = torch.tensor(x,dtype=torch.float)\n",
    "print(xt)\n",
    "print(type(x))\n",
    "print(type(xt))\n",
    "print(xt.dtype)\n",
    "y = xt.tolist() # this converts the pytorch tensor back to a python list\n",
    "print(y)\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55a75048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000, 0.7000, 0.8000,\n",
      "        0.9000, 1.0000])\n",
      "tensor([0.0000, 0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000, 0.7000, 0.8000,\n",
      "        0.9000])\n",
      "tensor([1.0000e+00, 1.0000e+01, 1.0000e+02, 1.0000e+03, 1.0000e+04, 1.0000e+05,\n",
      "        1.0000e+06, 1.0000e+07, 1.0000e+08, 1.0000e+09, 1.0000e+10])\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.linspace(0,1,steps=11,dtype=torch.float) # this generates [steps=11] many numbers, range from 0 to 1 \n",
    "x2 = torch.arange(0,1,0.1) # this generates (1-0)/0.1=10 numbers range from [start=0, end=1), note that the interval is not closed on the right\n",
    "y1 = torch.logspace(0,10,steps=11)\n",
    "print(x1)\n",
    "print(x2)\n",
    "print(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3478345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x1,y1) # this generates the cureve of y1 agaisnt x1\n",
    "plt.show()      # this show the genrerated curve    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d26f4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 1],\n",
      "        [3, 4],\n",
      "        [2, 1],\n",
      "        [3, 4]], dtype=torch.int32)\n",
      "tensor([[2, 1, 2, 1],\n",
      "        [3, 4, 3, 4]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "A=np.array([[2,1],[3,4]])\n",
    "At=torch.from_numpy(A)\n",
    "print(torch.cat((At,At),0)) # concatenate tensor At over columns \n",
    "print(torch.cat((At,At),1)) # concatenate tensor At over rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bdb1c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5797, 0.6876, 0.4676],\n",
      "        [0.9898, 0.4373, 0.8782]])\n",
      "tensor([[0.1078, 0.3501],\n",
      "        [0.8442, 0.5018]])\n"
     ]
    }
   ],
   "source": [
    "B = torch.rand(2,5)\n",
    "S = torch.chunk(B,2,1) # this splits the tensor B into two adjcent tensors by rows\n",
    "print(S[0])\n",
    "print(S[1]) # note that if the number of splits cannot be evely divided by the columns of rows, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae8a00dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is the original\n",
      "tensor([[11, 12, 13],\n",
      "        [21, 22, 23]])\n",
      "\n",
      "these are the collected, note how the new entries are chosen as per id_0 and id_1\n",
      "tensor([[21, 12, 23],\n",
      "        [11, 22, 13]])\n",
      "tensor([[13, 11, 12],\n",
      "        [22, 23, 21]])\n",
      "\n",
      "note how rows are chosen as per id_row\n",
      "tensor([[21, 22, 23],\n",
      "        [11, 12, 13]])\n",
      "\n",
      "note how columns are chosen as per id_col\n",
      "tensor([[12, 13, 11],\n",
      "        [22, 23, 21]])\n"
     ]
    }
   ],
   "source": [
    "AA = torch.tensor([[11,12,13],[21,22,23]])\n",
    "id_0 = torch.LongTensor([[1,0,1],[0,1,0]])\n",
    "id_1 = torch.LongTensor([[2,0,1],[1,2,0]])\n",
    "print('this is the original')\n",
    "print(AA)\n",
    "print('\\nthese are the collected, note how the new entries are chosen as per id_0 and id_1')\n",
    "print(torch.gather(AA,0,id_0))\n",
    "print(torch.gather(AA,1,id_1))\n",
    "id_row = torch.LongTensor([1,0]) # indices for row selection\n",
    "id_col = torch.LongTensor([1,2,0]) # indices for col selection\n",
    "print('\\nnote how rows are chosen as per id_row')\n",
    "print(torch.index_select(AA,0,id_row))\n",
    "print('\\nnote how columns are chosen as per id_col')\n",
    "print(torch.index_select(AA,1,id_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b353ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 1, 1, 0])\n",
      "tensor([[2],\n",
      "        [3]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wangyuan\\anaconda3\\envs\\workenv-37-1\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple) (Triggered internally at  ..\\torch\\csrc\\utils\\python_arg_parser.cpp:766.)\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "c = torch.randint(0,2,(5,)) # this generates 5 random integers in [0,2)\n",
    "print(c)\n",
    "print(torch.nonzero(c)) # this gives you which index in the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6952d3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is the original tensor\n",
      "tensor([[0.5797, 0.6876, 0.4676, 0.1078, 0.3501],\n",
      "        [0.9898, 0.4373, 0.8782, 0.8442, 0.5018],\n",
      "        [0.5797, 0.6876, 0.4676, 0.1078, 0.3501],\n",
      "        [0.9898, 0.4373, 0.8782, 0.8442, 0.5018]])\n",
      "\n",
      "this splits into chunks of size of 2 rows\n",
      "(tensor([[0.5797, 0.6876, 0.4676, 0.1078, 0.3501],\n",
      "        [0.9898, 0.4373, 0.8782, 0.8442, 0.5018]]), tensor([[0.5797, 0.6876, 0.4676, 0.1078, 0.3501],\n",
      "        [0.9898, 0.4373, 0.8782, 0.8442, 0.5018]]))\n",
      "\n",
      "this splits into chunks of size of 3 rows\n",
      "(tensor([[0.5797, 0.6876, 0.4676, 0.1078, 0.3501],\n",
      "        [0.9898, 0.4373, 0.8782, 0.8442, 0.5018],\n",
      "        [0.5797, 0.6876, 0.4676, 0.1078, 0.3501]]), tensor([[0.9898, 0.4373, 0.8782, 0.8442, 0.5018]]))\n",
      "\n",
      "this splits into chunks of size of different rows\n",
      "(tensor([[0.5797, 0.6876, 0.4676, 0.1078, 0.3501]]), tensor([[0.9898, 0.4373, 0.8782, 0.8442, 0.5018],\n",
      "        [0.5797, 0.6876, 0.4676, 0.1078, 0.3501]]), tensor([[0.9898, 0.4373, 0.8782, 0.8442, 0.5018]]))\n"
     ]
    }
   ],
   "source": [
    "# torch.split can split a tensor into smaller ones, \n",
    "# which is more flexible than torch.chunk, note the differences\n",
    "C = torch.cat((B,B),0)\n",
    "print('this is the original tensor')\n",
    "print(C)\n",
    "print('\\nthis splits into chunks of size of 2 rows')\n",
    "print(torch.split(C,2))\n",
    "print('\\nthis splits into chunks of size of 3 rows')\n",
    "print(torch.split(C,3))\n",
    "print('\\nthis splits into chunks of size of different rows')\n",
    "print(torch.split(C,[1,2,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61ed46c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is the tensor we gonna decomose, the transpose of C\n",
      "tensor([[0.5797, 0.9898, 0.5797, 0.9898],\n",
      "        [0.6876, 0.4373, 0.6876, 0.4373],\n",
      "        [0.4676, 0.8782, 0.4676, 0.8782],\n",
      "        [0.1078, 0.8442, 0.1078, 0.8442],\n",
      "        [0.3501, 0.5018, 0.3501, 0.5018]])\n",
      "\n",
      "now we decompose it into serperate tensors which are rows of the original tensor\n",
      "(tensor([0.5797, 0.9898, 0.5797, 0.9898]), tensor([0.6876, 0.4373, 0.6876, 0.4373]), tensor([0.4676, 0.8782, 0.4676, 0.8782]), tensor([0.1078, 0.8442, 0.1078, 0.8442]), tensor([0.3501, 0.5018, 0.3501, 0.5018]))\n",
      "\n",
      "now we decompose it into serperate tensors which are columns of the original tensor\n",
      "(tensor([0.5797, 0.6876, 0.4676, 0.1078, 0.3501]), tensor([0.9898, 0.4373, 0.8782, 0.8442, 0.5018]), tensor([0.5797, 0.6876, 0.4676, 0.1078, 0.3501]), tensor([0.9898, 0.4373, 0.8782, 0.8442, 0.5018]))\n"
     ]
    }
   ],
   "source": [
    "# using function torch.unbind(x,0 or 1) can decompose a tensor along rows or columns\n",
    "CT = C.transpose(0,1) # or use C.t() or =torch.tarnspose(C,0,1)\n",
    "print('this is the tensor we gonna decomose, the transpose of C')\n",
    "print(CT)\n",
    "print('\\nnow we decompose it into serperate tensors which are rows of the original tensor')\n",
    "print(torch.unbind(CT,0))\n",
    "print('\\nnow we decompose it into serperate tensors which are columns of the original tensor')\n",
    "print(torch.unbind(CT,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c4c5ab89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "here is the tensor A, an zero-tensor plus 2\n",
      "tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.]])\n",
      "torch.float32\n",
      "\n",
      "convert A from float32 to int8\n",
      "tensor([[2, 2, 2],\n",
      "        [2, 2, 2]], dtype=torch.int8)\n",
      "torch.int8\n",
      "\n",
      "here is the tensor B\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "\n",
      "here is the tensor B plus 0.5x an identity tensor\n",
      "tensor([[0.5000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.5000, 0.0000]])\n",
      "\n",
      "here we got A+B\n",
      "tensor([[2.5000, 2.0000, 2.0000],\n",
      "        [2.0000, 2.5000, 2.0000]])\n",
      "torch.float32\n",
      "note that the result is of float32\n"
     ]
    }
   ],
   "source": [
    "# Below shows how to do tensor sum\n",
    "print('\\nhere is the tensor A, an zero-tensor plus 2')\n",
    "Y1=torch.add(X_zeros,2) # this add a value of 2 into every single element in X_zeros\n",
    "print(Y1)\n",
    "print(Y1.dtype)\n",
    "\n",
    "print('\\nconvert A from float32 to int8')\n",
    "Y1 = Y1.char() # convert Y1 to 8-bit signed int, other e.g., byte, shor, long, float, double\n",
    "print(Y1)\n",
    "print(Y1.dtype)\n",
    "\n",
    "print('\\nhere is the tensor B')\n",
    "print(X_zeros)\n",
    "Y2=torch.add(X_zeros,X_eye,alpha=0.5) # this add X_eye*0.5 into tensor X_zeros\n",
    "print('\\nhere is the tensor B plus 0.5x an identity tensor')\n",
    "print(Y2)\n",
    "\n",
    "print('\\nhere we got A+B')\n",
    "print(torch.add(Y1,Y2))\n",
    "print(torch.add(Y1,Y2).dtype) # note that the add operation cast int into float\n",
    "print('note that the result is of float32') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "49290af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here we multiply an int8 tensor by 1.5 to get tensor C\n",
      "tensor([[3., 3., 3.],\n",
      "        [3., 3., 3.]])\n",
      "torch.float32\n",
      "note that entry-wise multiplication cast result to the dtype of higher level\n",
      "\n",
      "recall that this is tensor B, it is float32\n",
      "tensor([[0.5000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.5000, 0.0000]])\n",
      "\n",
      "now we multiply B by tensor C, B X C^T\n",
      "note that tow tensors to be multiplied must have same dtype\n",
      "tensor([[1.5000, 1.5000],\n",
      "        [1.5000, 1.5000]])\n"
     ]
    }
   ],
   "source": [
    "# below shows how to do multiplication and matrix multiplcation\n",
    "print('here we multiply an int8 tensor by 1.5 to get tensor C')\n",
    "Z = torch.mul(Y1,1.5) # torch.mul() do entry-wise multiplication\n",
    "print(Z)\n",
    "print(Z.dtype)\n",
    "print('note that entry-wise multiplication cast result to the dtype of higher level')\n",
    "\n",
    "# now let's do matrix multiplcation, two tensors must be same dtype\n",
    "print('\\nrecall that this is tensor B, it is float32')\n",
    "print(Y2)\n",
    "print('\\nnow we multiply B by tensor C, B X C^T')\n",
    "print('note that tow tensors to be multiplied must have same dtype')\n",
    "Z1 = torch.matmul(Y2,Z.t())\n",
    "print(Z1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5b0679c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is the tensor wo gonna use\n",
      "tensor([[-0.7628,  0.7653],\n",
      "        [ 0.5497,  0.8862]])\n",
      "\n",
      "now we compute expoential function values of an input tensor\n",
      "tensor([[0.4664, 2.1496],\n",
      "        [1.7327, 2.4259]])\n",
      "\n",
      "now restrict the elemtns of D to be no less than 0.1\n",
      "tensor([[0.1000, 0.7653],\n",
      "        [0.5497, 0.8862]])\n",
      "then compute log values\n",
      "tensor([[-2.3026, -0.2675],\n",
      "        [-0.5984, -0.1208]])\n",
      "\n",
      "we can also compute powers of a tensor using torch.pow\n",
      "tensor([[0.5819, 0.5857],\n",
      "        [0.3022, 0.7854]])\n"
     ]
    }
   ],
   "source": [
    "# now let's do entry-wise exponential and log functions\n",
    "D = torch.tensor([[-0.7628, 0.7653],[0.5497, 0.8862]])\n",
    "print('this is the tensor wo gonna use')\n",
    "print(D)\n",
    "exp_D = torch.exp(D)\n",
    "print('\\nnow we compute expoential function values of an input tensor')\n",
    "print(exp_D)\n",
    "\n",
    "# now we restrict the elemtns of D to be positive to compute log funciton\n",
    "D1 = torch.clamp(D,min=0.1)\n",
    "print('\\nnow restrict the elemtns of D to be no less than 0.1')\n",
    "print(D1)\n",
    "print('then compute log values')\n",
    "print(torch.log(D1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "06f8f3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "we can also compute entry-wise powers of a tensor using torch.pow\n",
      "tensor([[-0.7628,  0.7653],\n",
      "        [ 0.5497,  0.8862]])\n",
      "below is the entry-wise squares of tensor D\n",
      "tensor([[0.5819, 0.5857],\n",
      "        [0.3022, 0.7854]])\n",
      "\n",
      "and also computing the entry-wise square roots, e.g. the square-root of a diagonal matrix of 2 is\n",
      "tensor([[1.4142, 0.0000],\n",
      "        [0.0000, 1.4142]])\n"
     ]
    }
   ],
   "source": [
    "print('\\nwe can also compute entry-wise powers of a tensor using torch.pow')\n",
    "print(D)\n",
    "print('below is the entry-wise squares of tensor D')\n",
    "print(torch.pow(D,2))\n",
    "print('\\nand also computing the entry-wise square roots, e.g. the square-root of a diagonal matrix of 2 is')\n",
    "print(torch.sqrt(torch.mul(torch.eye(2),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "029e5faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall that we are using tensor D which is\n",
      "tensor([[-0.7628,  0.7653],\n",
      "        [ 0.5497,  0.8862]])\n",
      "and its entry-wise sigmoid value is\n",
      "tensor([[0.3180, 0.6825],\n",
      "        [0.6341, 0.7081]])\n"
     ]
    }
   ],
   "source": [
    "# now let's compute entry-wise value of sigmoid function\n",
    "print('recall that we are using tensor D which is')\n",
    "print(D)\n",
    "print('and its entry-wise sigmoid value is')\n",
    "print(torch.sigmoid(D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b271e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
